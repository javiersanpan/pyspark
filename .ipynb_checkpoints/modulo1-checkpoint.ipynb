{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f61184-517f-4b0a-abc8-47bfc4ae21ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/23 18:52:54 WARN Utils: Your hostname, MacBook-Air-de-Javier-2.local resolves to a loopback address: 127.0.0.1; using 10.43.60.150 instead (on interface en0)\n",
      "23/10/23 18:52:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/23 18:52:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.43.60.150:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Hola mundo Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1067fe090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estableciendo variable de entorno\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-16.jdk/Contents/Home\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/homebrew/Cellar/apache-spark/3.5.0/libexec\"\n",
    "\n",
    "#Buscando e inicializando la instalación de Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "#Probando PySparl\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from typing import List\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"Hola mundo Spark\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55266d7-f938-4d27-97d1-56b4cc61d473",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c03b75e-949e-40d6-972d-8989a5846f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/23 19:14:49 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "23/10/23 19:14:49 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "23/10/23 19:14:50 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    }
   ],
   "source": [
    "regression_data = spark.read.format(\"libsvm\").load(\"./sample_linear_regression_data.txt\")\n",
    "\n",
    "classification_data = spark.read.format(\"libsvm\").load(\"./sample_binary_classification_data.txt\")\n",
    "\n",
    "clustering_data = spark.read.format(\"libsvm\").load(\"./sample_kmeans_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f353846-6275-4e41-86ea-489e8c0c8269",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c183ff11-e4a7-4819-a00d-b2ce6542bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.3229251667740594,-0.3438548034562219,1.915601702345841,0.05288058680386255,0.765962720459771,0.0,-0.15105392669186676,-0.21587930360904645,0.2202536918881343]\n",
      "Intercept: 0.15989368442397356\n",
      "numIterations: 6\n",
      "objectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.49363616643404634, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -9.889232683103197|\n",
      "|  0.5533794340053553|\n",
      "|  -5.204019455758822|\n",
      "| -20.566686715507508|\n",
      "|    -9.4497405180564|\n",
      "|  -6.909112502719487|\n",
      "|  -10.00431602969873|\n",
      "|  2.0623978070504845|\n",
      "|  3.1117508432954772|\n",
      "|  -15.89360822941938|\n",
      "|  -5.036284254673026|\n",
      "|  6.4832158769943335|\n",
      "|  12.429497299109002|\n",
      "|  -20.32003219007654|\n",
      "|    -2.0049838218725|\n",
      "| -17.867901734183793|\n",
      "|   7.646455887420495|\n",
      "| -2.2653482182417406|\n",
      "|-0.10308920436195645|\n",
      "|  -1.380034070385301|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.189077\n",
      "r2: 0.022861\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(regression_data)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9957b-755c-49d1-b777-4c007f041ec6",
   "metadata": {},
   "source": [
    "# Regresión logística binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2b32172-cf86-4208-86b5-8e78ef4b47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (692,[272,300,323,350,351,378,379,405,406,407,428,433,434,435,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.52068987138421e-05,-8.115773146847101e-05,3.814692771846369e-05,0.0003776490540424337,0.00034051483661944103,0.0005514455157343105,0.0004085386116096913,0.000419746733274946,0.0008119171358670028,0.0005027708372668751,-2.3929260406601844e-05,0.000574504802090229,0.0009037546426803721,7.818229700244018e-05,-2.1787551952912764e-05,-3.4021658217896256e-05,0.0004966517360637634,0.0008190557828370367,-8.017982139522704e-05,-2.7431694037836214e-05,0.0004810832226238988,0.00048408017626778765,-8.926472920011488e-06,-0.00034148812330427335,-8.950592574121486e-05,0.00048645469116892167,-8.478698005186209e-05,-0.0004234783215831763,-7.29653577763134e-05])\n",
      "Intercept: -0.5991460286401435\n",
      "Multinomial coefficients: 2 X 692 CSRMatrix\n",
      "(0,272) 0.0001\n",
      "(0,300) 0.0001\n",
      "(0,350) -0.0002\n",
      "(0,351) -0.0001\n",
      "(0,378) -0.0003\n",
      "(0,379) -0.0002\n",
      "(0,405) -0.0002\n",
      "(0,406) -0.0004\n",
      "(0,407) -0.0002\n",
      "(0,433) -0.0003\n",
      "(0,434) -0.0005\n",
      "(0,435) -0.0001\n",
      "(0,456) 0.0\n",
      "(0,461) -0.0002\n",
      "(0,462) -0.0004\n",
      "(0,483) 0.0001\n",
      "..\n",
      "..\n",
      "Multinomial intercepts: [0.27505875857181117,-0.27505875857181117]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(classification_data)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(classification_data)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067dc67-26b9-4cf3-9ad1-6a5392ef394d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
